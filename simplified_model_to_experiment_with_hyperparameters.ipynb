{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a51468-c526-445a-8aa4-7e49ea97cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.compat.v1.losses import sparse_softmax_cross_entropy as sparse_categorical_crossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e281e5c-79a2-483e-8476-3cd993c904c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom VGG-16 model with shorter depth, increased max pooling, and dropout\n",
    "def modified_vgg16(input_shape=(224, 224, 3), num_classes=13):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Block 1\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='valid', input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Dense layer\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    \n",
    "    # Dropout for Regularization\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the modified model\n",
    "modified_model = modified_vgg16(input_shape=(224, 224, 3), num_classes=13)\n",
    "\n",
    "# Compile the model\n",
    "modified_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "302d1087-e7fd-45dd-a186-5db22466bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Step 1: Store file paths and split into training and test\n",
    "main_folder = \"C:\\\\Dataset\"\n",
    "\n",
    "# List to store image file paths and corresponding labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Traverse through the directory structure\n",
    "for brand_folder in os.listdir(main_folder):\n",
    "    brand_path = os.path.join(main_folder, brand_folder)\n",
    "    \n",
    "    if os.path.isdir(brand_path):\n",
    "        for image_file in os.listdir(brand_path):\n",
    "            # Check if the file is an image (you might want to add more extensions)\n",
    "            if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_path = os.path.join(brand_path, image_file)\n",
    "                image_paths.append(image_path)\n",
    "                labels.append(brand_folder)  # Assuming brand name is the label\n",
    "\n",
    "# Convert labels to numerical values using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train_paths, X_test_paths, y_train, y_test = train_test_split(image_paths, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cda3841a-e4d2-4bd9-8e12-09f073e42d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 130\n",
    "\n",
    "# Create a list to store the loaded batches\n",
    "train = []\n",
    "\n",
    "# Load all saved batches\n",
    "for i in range(num_batches):\n",
    "    # Define the file name or path for each batch\n",
    "    load_path = f'C:\\\\Users\\\\arava\\\\OneDrive\\\\Desktop\\\\New folder\\\\X_train\\\\processed_batch_{i}.npy'\n",
    "    \n",
    "    # Load the batch and append it to the list\n",
    "    loaded_batch1 = np.load(load_path)\n",
    "    train.append(loaded_batch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c58b3146-b30e-4d55-9a8a-06fb07c9513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 33\n",
    "\n",
    "# Create a list to store the loaded batches\n",
    "test = []\n",
    "\n",
    "# Load all saved batches\n",
    "for i in range(num_batches):\n",
    "    # Define the file name or path for each batch\n",
    "    load_path = f'C:\\\\Users\\\\arava\\\\OneDrive\\\\Desktop\\\\New folder\\\\X_test\\\\processed_batch_{i}.npy'\n",
    "    \n",
    "    # Load the batch and append it to the list\n",
    "    loaded_batch2 = np.load(load_path)\n",
    "    test.append(loaded_batch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dde29123-2b3c-4beb-9e7e-4ba0e032c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)\n",
    "loaded_y_train = np.load('y_train.npy')\n",
    "loaded_y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1fbe395-14d6-42e3-93f5-598f06245144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# File paths for processed image data batches\n",
    "image_folder = 'C:\\\\Users\\\\arava\\\\OneDrive\\\\Desktop\\\\New folder\\\\X_train\\\\'\n",
    "num_batches = 129\n",
    "\n",
    "# Load processed image data batches\n",
    "image_data_batches = [np.load(os.path.join(image_folder, f'processed_batch_{i}.npy')) for i in range(num_batches)]\n",
    "\n",
    "# Load additional individual images batch\n",
    "additional_images_batch = np.load(os.path.join(image_folder, 'processed_batch_129.npy'))\n",
    "\n",
    "# Concatenate all image data\n",
    "all_image_data = np.concatenate(image_data_batches + [additional_images_batch])\n",
    "\n",
    "# Load labels from 'y_train.npy' without the image folder path\n",
    "labels = np.load('y_train.npy')  # Adjust the path accordingly\n",
    "\n",
    "# Convert labels to categorical format\n",
    "labels_categorical = to_categorical(labels, num_classes=13) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3300abae-0067-4a66-a4b5-ebbd3155f6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "130/130 [==============================] - 700s 5s/step - loss: 6.6624 - accuracy: 0.1458\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 685s 5s/step - loss: 2.5262 - accuracy: 0.1649\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 687s 5s/step - loss: 2.5131 - accuracy: 0.1651\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 682s 5s/step - loss: 2.5101 - accuracy: 0.1651\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 681s 5s/step - loss: 2.5069 - accuracy: 0.1651\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = modified_model.fit(\n",
    "    all_image_data, labels_categorical,\n",
    "    epochs=5,  \n",
    "    batch_size=32  \n",
    ")\n",
    "\n",
    "# Save the trained model weights and biases\n",
    "modified_model.save_weights('model_weights.h5')\n",
    "\n",
    "# Save the model architecture and configuration\n",
    "with open('model_config.json', 'w') as json_file:\n",
    "    json_file.write(modified_model.to_json())\n",
    "\n",
    "# Save the training history for future analysis or plotting\n",
    "np.save('training_history.npy', history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6132f00-3aec-4313-99b4-de1ed9d8a08b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
